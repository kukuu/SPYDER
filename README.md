# SPYDER

https://www.energytariffscheck.com/ 

SPYDER is an AI-driven platform for the energy sector. It was designed to ingest, process, and make sense  of complex energy tariff data to provide actionable insights - a similar challenge to making sense of contract and generation data for policy compliance and reporting.   
 
A Net Zero initiative Price comparison platform. it is  designed to helps you find the best electricity tariff at the most competitive price. Compare different tariffs, check prices and choose the right option to save on energy bills. The Reader also serves as a forecasting system, a settlement tool and a Net Zero initiative - empowering businesses and consumers with actionable insights for reducing carbon emissions and adopting sustainable energy solutions.   

Hosted on EnergyTariffsCheck.com - https://www.energytariffscheck.com/ , **SPYDER** is a digital representation of a physicalÂ energy meter reader utilising real-time energy data, AI-driven analytics, and user-friendly tools to compare tariffs, track consumption,  simulate scenarios, predict outcomes, enable forecasting, facilitateÂ predictive maintenance, and recommend cost-effective renewable energy options.  
  
We have integrated dynamic carbon footprint tracking, personalised energy-saving strategies, and compliance frameworks into a scalable Next.js, TypeScript and Python platform - helping users align sustainability goals with practical, measurable actions.  

**SPYDER**â€™s mission is to bridge the gap between ambition and implementation in the transition to carbon neutrality. By partnering with green energy providers and leveraging smart algorithms and best practices in OOP, Design Thinking, AI and Machine Learning, the platform is  enabling users to cut costs through personalisation, forecasting, predictive analysis and accelerated maintenance workflows while speeding their Net Zero progress.  

This project reflects my passion for using technology as a dual force for environmental and economic impact - turning complex energy decisions into clear, actionable steps for a sustainable future. It follows my work on the OFGEM MHHR initiative. The MHHR is a  transformative energy sector initiative modernising the UKâ€™s electricity settlement system to half-hourly intervals, enabling accurate billing, grid flexibility, and smarter energy use. It paves the way for renewable integration and cost savings for consumers. 


### Energy Meter Reader - Digital Twin ( V2 - Node)

_Repository_ :  
- https://github.com/kukuu/digital-twin-v2 (**PRIVATE** - NodeJS)

This  Digital Twin Energy Meter Reader is a dynamic, virtual representation of a physical Energy Meter Reader. It mirrors the real-world entity by continuously collecting data from sensors, real-time data streams, data lakes, IoT devices, and other sources. The data is then processed and analyzed to create a digital replica that accurately reflects the behavior, status, and condition of its physical counterpart. By leveraging advanced technologies such as artificial intelligence, machine learning, and predictive analytics, digital twins can simulate various scenarios and predict future outcomes. This enables stakeholders to monitor performance, diagnose issues, optimize processes, and make data-driven decisions in real-time.




### The Nut Cracker  (V4 - Python)

_Repository_ :  https://github.com/kukuu/digital-twin-PV4- (**PRIVATE** Python)

The primary objective of **Nut Cracker** (Digital Twin V4) is to leverage Artificial Intelligence (AI) and Machine Learning (ML), to streamline the transaction process involving data generation, processing,and transformation - ETL. This process focuses on real-time data sourced from distributed and disparate networks and systems. It's ML lifecycle covers data preparation and model training to deployment and monitoring.

- Key functionalities include:

1. Predictive Analysis: Utilizing AI to identify patterns, trends, and anomalies such as spikes, valleys, and boundaries, enabling predictive maintenance and detecting outliers or tampered data.

2. Visualization and Reporting: Generating comprehensive visualization reports, graphs, and documentation to review real-time system performance. These tools aid in forecasting and enhancing productivity by providing actionable insights, real-time monitoring, optimisation, improving efficiency, reducing costs, and enhancing decision-making.

Nut Cracker aims to integrate AI and ML  technologies to optimize data workflows, deliver predictive insights, and provide robust visualization tools for performance monitoring and future planning. As a high-volume throughput system, it exemplifies real-time asynchronous data processing capability ensuring scalability, reliability, flexibility, observability, security and addresses challenges like schema evolution and fault tolerance.

NodeJS, JavaScript,  Python, Machine Learning, Artificial Inrtelligence, Event Driven Concurrency, RDBMS / NoSQL technologies (e.g. MySQL, Redis, DynamoDB), and cloud technologies are core in this innovation.

### Key Features LLM Integration

âœ… Ask Jim:  Custom Domain AI Engine, ML, LLM  RAG Pipeline - https://github.com/kukuu/ask-JIM.

âœ… Predictive Maintenance: LLM analyses trends to flag anomalies (e.g., meter failures).

âœ… Natural Language Queries (Semantic SEARCH): Users ask, "Show worst-performing meters this week" via chat.

âœ… Automated Reports: LangChain generates summaries from Supabase data.

âœ… Simulation Scenarios: "What if meter load increases by 20%?" â†’ LLM runs digital twin simulations.


## Technologies and Practices
  
- Node 
- Python
- TypeScript
- REACT
- Supabase
- PostGreSQL
- MongoDB 
- Apache KAFKA
- RabbitMQ
- Apache Flink
- PRISMA ORM
- Microservices
- NextJS
- GraphQL
- Websocket
- EXPRESS
- Prometheus
- Elasticsearch
- KIBANA
- Jenkins
- Kubernetes
- Docker
- Logstash
- Grafana
- Render
- Vercel
- AWS
- GCP
- AZURE
- ARIMA
- LSTM
- Datadog
- OWASP ZAP
- SENTRY
- SONARCUBE
- Jest
- Cypress
- Tailwind CSS
- Material UI
- JIRA
- Confluence
- Miro
- CI/CD
- Agile


## Scaling
First priority: Implement comprehensive **tariff calculation tests** + **database connection pooling** - these will deliver immediate stability gains while you plan larger architectural changes.

- ðŸ“Š **Key Performance Indicators**

  - API Response: < 200ms for tariff comparisons

  - Concurrent Users: Scale to 10,000+ simultaneous comparisons

  - Test Coverage: 80%+ on core tariff logic

  - Deployment: Zero-downtime deployments via blue/green

- Phase 1: Immediate Wins (2-4 weeks)

  - Extract tariff calculation engine to isolated microservice

  - Implement Circuit Breaker pattern for external API calls

  - Add structured logging with correlation IDs

- Phase 2: Medium-term (1-3 months)

  - Migrate to event-driven architecture (price update events)

  - Implement CQRS for read/write separation

  - Add feature flags for gradual rollout

- Phase 3: Strategic (3-6 months)

  - Decompose monolith into domain services:

  - tariff-service (calculations)

  - user-service (profiles/usage)

  - comparison-engine (matching logic)



### Fullstack Flow 

https://github.com/kukuu/blue-prints/blob/main/full-stack-flow.md

## Pipeline Architecture - Nut Cracker (V4 - Python)

```


               DATA INGESTION LAYER
+------------------------------------------------------+
|   Input Sources                                      |
| - Synthetic Data                                     |
| - Excel Files with Meter Consumption Data            |
| - Real-time Streaming of Meter Readings              |
| - API Endpoints for External Data Sources(in-scope)  |
+------------------------------------------------------+
|   Tools                                              |
| - Python (Pandas, OpenPyXL for spreadsheets)         |
| - Kafka or RabbitMQ for real-time streaming          |
+------------------------------------------------------+
                    |
            DATA TRANSFORMATION LAYER
                    |                            
+-------------------------------------------------+
|   Data Cleansing                                |
| - Handle missing,duplicate or invalid meter     |
|    readings                                     |
| - Standardize timestamps and formats            |
+-------------------------------------------------+
|   Data Transformation                           |
| - Aggregate daily, weekly, and monthly readings |
| - Create derived metrics (e.g., avg consumption)|
+-------------------------------------------------+
|   Tools                                         |
| - Python (NumPy, Pandas)                        |
| - PySpark for large-scale processing (Hadoop)   |
+-------------------------------------------------+
                  |
            STORAGE LAYER
                  |
+-------------------------------------------------+
|   Database                                      |
| - PostgreSQL or MySQL for structured data       |
| - Separate tables for sources A, B, and C       |
| - Indexed columns for timestamp-based queries   |
+-------------------------------------------------+
|   Data Lake                                     |
| - S3/Blob Storage for raw and transformed data  |
+-------------------------------------------------+
                   |
             ARCHIVAL SYSTEM
                   |
+-------------------------------------------------+
|   Archival Process                              |
| - Move data older than 30 days to archive folder|
| - Compress files to reduce storage size         |
+-------------------------------------------------+
|   Tools                                         |
| - Python (Schedule/Crontab for automation)      |
| - Cloud Storage (AWS S3, GCP Bucket)            |
+-------------------------------------------------+
                   |
         BATCH PROCESSING & NOTIFICATION LAYER
                   |
+-------------------------------------------------+
|   Scheduled Jobs                                |
| - Batch export of data to stakeholders          |
| - Generate and email reports (PDF/CSV)          |
+-------------------------------------------------+
|   Notification System                           |
| - Send reports to email via SMTP/Payment Gateway |
| - Integrate email notifications with SES/SendGrid|
+-------------------------------------------------+
|   Tools                                         |
| - Python (smtplib, pandas for formatting emails)|
| - Celery + RabbitMQ for batch processing        |
+-------------------------------------------------+
                   |
            MONITORING AND LOGGING
                   |
+-------------------------------------------------+
|   Logging                                       |
| - Track ingestion errors, transformation issues |
| - Log storage/archival successes or failures    |
+-------------------------------------------------+
|   Monitoring                                    |
| - Prometheus for pipeline metrics               |
| - Grafana for real-time dashboards and alerts   |
+-------------------------------------------------+

```


## AI Tools and Frameworks:


### Generative AI:

- Tools: OpenAI, LLM, GPT, Cohere,  Anthropic for natural language processing (NLP) tasks.

- Frameworks for building conversational AI: Rasa or Dialogflow.

- Machine Learning Frameworks:

i. TensorFlow or PyTorch for developing and deploying machine learning models.

ii. scikit-learn for traditional ML algorithms.

- AI-Driven Solutions:

i. Retrieval-Augmented Generation (RAG) systems to enhance information retrieval and generation.

ii. Building Agentic Applications that automate workflows and decision-making processes.

- Data Processing and Analytics:

- Tools: Pandas, NumPy, and Spark for data preprocessing and analysis.

- ELK Stack (Elasticsearch, Logstash, Kibana) for data visualisation and monitoring.

### Ask JIM

"Ask Jim" is an AI-powered agile assistant that integrates with communication platforms like Slack and Microsoft Teams. It provides real-time guidance on agile methodologies and helps teams streamline their development processes.

https://github.com/kukuu/ask-JIM

### Backend Integration Practices

   
- API Development: 
Creating backend APIs (Application Programming Interfaces) that define the protocols, data formats, and operations required for communication between different systems. This involves designing and implementing RESTful APIs, SOAP APIs, GraphQL APIs, or other types of APIs based on the integration requirements. 

-  Data Transformation and Mapping:
Converting data formats, structures, and representations to ensure compatibility between different systems. This may involve transforming data from one schema to another, schema evolutio/managing breaking changes, mapping fields between systems, or performing data validation and cleansing. ORMs are versatile as middlewares in ETL tasks.

...more: https://github.com/kukuu/managing-evolving-SCHEMA--contracts

- Message Queuing and Event-Driven Integration: 
Implementing messaging systems and event-driven architectures to enable asynchronous communication and decoupling between components. This involves setting up message queues, event brokers, or publish-subscribe mechanisms to handle communication between systems.

- Security and Authentication: 
Implementing authentication and authorization mechanisms to ensure secure access and data protection during integration. This may involve implementing OAuth, token-based authentication (JWT), or other security measures to authenticate and authorize requests - using SSL, Firewalls.

- Error Handling and Logging: 
Implementing error handling mechanisms to capture and handle exceptions, failures, and unexpected events during integration. This includes logging errors, generating error reports, and implementing retry mechanisms to handle transient failures.

- CI/CD and Integration Testing: 
Designing and conducting integration tests to ensure the seamless functioning and interoperability of integrated components. This involves testing data exchange, communication protocols, error handling, and overall system behavior.

- Monitoring and Performance Optimization: 
Setting up monitoring systems to track the performance, availability, and health of the integrated system. This includes monitoring API response times, identifying performance bottlenecks, and optimizing system performance through caching, load balancing, rate limiting or other techniques.

- Documentation: 
Creating documentation, guidelines, and technical specifications for the integrated system. This helps developers, administrators, and other stakeholders understand the integration process, usage of APIs, data structures, and configurations.

## Tariff Calculation Tests and DB Pooling


## Related resources:

- Price Comparison: https://www.energytariffscheck.com/ | https://github.com/kukuu/digital-twin-v2 (**PRIVATE**)
- Conveyor Belt Simulation: https://github.com/kukuu/IIoT-Digital-Twin-Simulation
- FIFA World Cup 2022: https://github.com/kukuu/FIFA-SaaS-NotificationPlatform-Qatar-WorldCup-2022
- SPIDER Navigation System (SNS): https://github.com/kukuu/spider-navigation-system
- Love Joint: https://www.lovejoint.store/ | https://github.com/kukuu/lovejoint (**PRIVATE**) | https://github.com/kukuu/lovejoint-docs
- AZZOTTO Movies: https://www.azzottomovies.com/trailers | https://github.com/kukuu/azzotto-movies (**PRIVATE**)
- Integration & Cloud Migration: https://github.com/kukuu/integration (**PRIVATE**)



